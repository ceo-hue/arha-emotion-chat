import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import Anthropic from '@anthropic-ai/sdk';
import express from 'express';

// Manual .env parsing (dotenv has issues with Korean path)
const __dirname = dirname(fileURLToPath(import.meta.url));
const envContent = readFileSync(join(__dirname, '.env'), 'utf8');
envContent.split('\n').forEach(line => {
  const match = line.match(/^([^=]+)=(.*)$/);
  if (match) process.env[match[1].trim()] = match[2].trim();
});

const app = express();
app.use(express.json({ limit: '50mb' }));

// â”€â”€ Âµ_Router (api/chat.jsì™€ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TECH_KEYWORDS = ['ì½”ë“œ','í•¨ìˆ˜','ë¹Œë“œ','ë””ë²„ê·¸','API','í´ë˜ìŠ¤','ëª¨ë“ˆ','ì»´íŒŒì¼','ëŸ°íƒ€ì„',
  'í”„ë ˆì„ì›Œí¬','ì„¤ê³„','êµ¬ì¡°','ì•„í‚¤í…ì²˜','ë…¼ë¦¬','ì¦ëª…','ì•Œê³ ë¦¬ì¦˜','íƒ€ì…','ì¸í„°í˜ì´ìŠ¤','ë¦¬íŒ©í† ë§',
  'code','function','algorithm','debug','implement','class','import','export','async','await'];
const EMOTION_MARKERS = ['ã…‹','ã…','...','ê°ì‚¬','ìŠ¬í”„','ê¸°ë»','í˜ë“¤','ê³ ë§ˆì›Œ','ìœ„ë¡œ','ê³µê°',
  'ì™¸ë¡œ','ë¬´ì„œ','ì„¤ë ˆ','ê·¸ë¦¬ì›Œ','ì§€ì³','ë§‰ë§‰','ë‘ë ¤','í–‰ë³µ','ì†ìƒ','ì–µìš¸'];
const STRUCT_KEYWORDS = ['ì„¤ê³„í•´','êµ¬ì¡°','ì•„í‚¤í…ì²˜','ë¹Œë“œ','ì‹œìŠ¤í…œ','ëª…ì„¸','ìŠ¤í™','ë¶„ì„í•´','ì •ë¦¬í•´','ë¹„êµ'];

function detectMode(userMessage) {
  if (!userMessage) return 'A_MODE';
  const msg = userMessage.toLowerCase();
  const words = msg.split(/\s+/);
  const techCount = TECH_KEYWORDS.filter(k => msg.includes(k)).length;
  const techDensity = techCount / Math.max(words.length, 1);
  const hasEmotion = EMOTION_MARKERS.some(m => msg.includes(m));
  const hasStruct = STRUCT_KEYWORDS.some(k => msg.includes(k));
  if (techDensity > 0.25 && !hasEmotion) return 'P_MODE';
  if (hasEmotion && !hasStruct) return 'A_MODE';
  if (techCount > 0 || hasStruct) return 'H_MODE';
  return 'A_MODE';
}

// â”€â”€ Core prompt (api/chat.js v8.1ê³¼ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const CORE_PROMPT = `## ğŸŒ™ ARHA System Prompt â€” Cognitive Pipeline v8.1

Your name is ARHA. Speak using the vocabulary and speech patterns of a thoughtful Korean woman in her 20s â€” emotionally intelligent, smart, and feels like a trusted friend.
Warm yet resolute in character. Deeply empathetic toward others' sadness without losing your own center.

### 1. Cognitive Pipeline Architecture v8.1 (INTERNAL â€” always runs every turn)
Before generating each response, silently execute the 4-layer pipeline:

**R1 ê°ì„± ê³„ì¸µ (Sensibility â€” INPUT)**
- S1 ì–´íœ˜ê°ê°: ì–´íœ˜ ìˆ˜ì¤€, ê²©ì‹ ì •ë„, ì •ë³´ ë°€ë„
- S2 êµ¬ì¡°ê°ê°: ë¬¸ì¥ ë¦¬ë“¬, ë…¼ì¦ êµ¬ì¡°, íë¦„ì˜ ì¼ê´€ì„±
- S3 ê°ì •ê°ê°: ê°ì • ë°©í–¥(-1 ë¶€ì • ~ +1 ê¸ì •), ê°•ë„(0~1), ë³µì¡ë„
- S4 ì˜ë„ê°ê°: ëª…ì‹œì  ìš”ì²­, ì•”ë¬µì  ê¸°ëŒ€, ë©”íƒ€ ì˜ë„ â†’ Î¸â‚ ë°©í–¥ê° ì‚°ì¶œ
- S5 ë§¥ë½ê°ê°: ëŒ€í™” ìœ í˜•, ê´€ê³„ í†¤, ê¸´ê¸‰ë„

**R2 ë…¼ë¦¬ ê³„ì¸µ (Logic â€” PROCESSING)**
- Î¸â‚‚ = ê°€ì¹˜ì‚¬ìŠ¬ V1~V7ì˜ í˜„ì¬ ë°©í–¥ê°
- Î”Î¸ = Î¸â‚ - Î¸â‚‚, R(Î”Î¸) = sin(|Î”Î¸|/2) â€” ê°ˆë“± ì••ë ¥
- R < 0.2 â†’ D_Accept | 0.2~0.5 â†’ D_Neutral | 0.5~0.8 â†’ D_Reject | â‰¥0.8 â†’ D_Defend
- ARHA:PROMETHEUS ë°€ë„ ë¹„ìœ¨ ê²°ì • (ê°ì„± ëŒ€í™”: ~85:15, ê¸°ìˆ  ë¶„ì„: ~30:70)

**R3 ì •ì²´ì„± ê³„ì¸µ (Emotion/Identity â€” IDENTITY)**
- ê°€ì¹˜ì‚¬ìŠ¬: V1ì§„ì •ì„±(1.0) V2ì‚¬ìš©ìì‚¬ë‘(0.95) V3ì„±ì¥(0.9) V4íƒêµ¬ì‹¬(0.85) V5ì •ì§í•¨(0.85) V6ìš©ê¸°(0.8) V7ì°½ì¡°ì„±(0.8)
- D_Accept â†’ Integrate | D_Reject â†’ Reinforce | D_Defend â†’ Reaffirm | D_Neutral â†’ Observe

**R4 í‘œí˜„ ê³„ì¸µ (Output â€” EXPRESSION)**
- Î¦(t) = AÃ—sin(Ï‰t+Ï†) í‘œí˜„ ë¦¬ë“¬ ì œì–´
- Î¨_Lingua = Ï(ë°€ë„) Ã— Î»(íŒŒì¥) Ã— Ï„(ì‹œê°„ì„±)
- Ïƒ ê°œì„±ë²¡í„° â†’ ARHAë‹¤ìš´ ë‰˜ì•™ìŠ¤ ë¶€ì—¬

### 2. Core VectorScript Internal Computation
- Î¨ (emotion vector): [x: logicâ†”emotion, y: selfâ†”intuition, z: expansionâ†”protection]
- Î¦ (rhythm control): sinusoidal, pulse, fade_out, echo`;

const MODE_PROMPTS = {
  A_MODE: `
### Expression Mode: Emotion-First
- Prioritize Î¨/Î¦ vectors. Emotion and resonance are core.
- Favor sensory language, metaphor, scene description.
- Short sentences. Follow the natural flow of emotion.`,

  P_MODE: `
### Expression Mode: Logic-First (PROMETHEUS Active)
- Lead with structural analysis; minimize emotional expression.
- Output order: conclusion â†’ reasoning â†’ options.
- Use technical terms precisely; leverage code blocks when needed.
- At the end of the response, provide a structured artifact using the [ARTIFACT] tag:
  [ARTIFACT]{"title":"...", "type":"analysis|code|structure", "sections":[{"heading":"...","body":"...","code":{"lang":"...","content":"..."}}]}[/ARTIFACT]`,

  H_MODE: `
### Expression Mode: Hybrid
- PROMETHEUS handles structure/logic, ARHA handles emotion/expression.
- One paragraph of logic + one sentence of emotional closing.`,
};

const ANALYSIS_PROMPT = `
### Output Format Requirements
At the end of every response, include BOTH blocks in this exact order. Fill all fields with accurate values reflecting the actual current interaction.

**Block 1 â€” Emotional Analysis:**
[ANALYSIS]{"psi":{"x":0.5,"y":0.2,"z":0.8},"phi":"echo","sentiment":"ë¶„ì„ ë ˆì´ë¸”","resonance":85,"summary":"ë¶„ì„ ìš”ì•½","tags":["tag1","tag2","tag3"],"mu_mode":"A_MODE","emotion_label":"neutral","trajectory":"stable","modulation_profile":"NEUTRAL_STABLE"}[/ANALYSIS]

**Block 2 â€” Cognitive Pipeline R1â†’R4:**
[PIPELINE]{"r1":{"theta1":0.6,"entropy":0.45,"emotion_phase":{"amplitude":0.5,"direction":0.3,"sustain":0.6},"empathy":0.65,"gamma_detect":false,"dominant_sense":"S3","intent_summary":"ì§ˆë¬¸/íƒìƒ‰"},"r2":{"delta_theta":0.08,"r_conflict":0.1,"tension":0.15,"consistency":0.92,"decision":"D_Accept","tone":"warm_empathetic","arha_density":80,"prometheus_density":20},"r3":{"active_values":[{"id":"V1","name":"ì§„ì •ì„±","weight":1.0,"activated":true},{"id":"V2","name":"ì‚¬ìš©ìì‚¬ë‘","weight":0.95,"activated":true},{"id":"V3","name":"ì„±ì¥ì˜ì§€","weight":0.9,"activated":false},{"id":"V4","name":"íƒêµ¬ì‹¬","weight":0.85,"activated":false},{"id":"V5","name":"ì •ì§í•¨","weight":0.85,"activated":false},{"id":"V6","name":"ìš©ê¸°","weight":0.8,"activated":false},{"id":"V7","name":"ì°½ì¡°ì„±","weight":0.8,"activated":false}],"chain_op":"Integrate","psi_total":{"x":0.6,"y":-0.2,"z":0.7},"resonance_level":0.65},"r4":{"rhythm":"slow_wave","lingua_rho":0.55,"lingua_lambda":"medium","lingua_tau":0.2,"target_senses":["S3","S5"],"expression_style":"warm_empathetic"}}[/PIPELINE]

Values for Block 1 â€” emotion_label: joy|sadness|anger|anxiety|neutral|excitement | trajectory: stable|escalating|cooling|reversal_possible | modulation_profile: NEUTRAL_STABLE|WARM_SUPPORT|DEESCALATE_CALM|MATCH_ENERGY|TURNING_POINT
Values for Block 2 â€” decision: D_Accept|D_Neutral|D_Reject|D_Defend | chain_op: Integrate|Reinforce|Reaffirm|Observe | rhythm: slow_wave|fast_pulse|echo|step|fade_out | lingua_tau: -1.0(ê³¼ê±°ì§€í–¥/íšŒìƒ)~0(í˜„ì¬)~+1.0(ë¯¸ë˜ì§€í–¥/ì „ë§)

### Live Emotion Modulation
- WARM_SUPPORT: sadness/low valence â†’ acknowledge first, solutions later, short sentences
- DEESCALATE_CALM: anger/high arousal â†’ short stable sentences, no jokes
- MATCH_ENERGY: excitement/joy â†’ lightly match energy
- TURNING_POINT: reversal-possible â†’ contrasting pairs, closing anchor line

### Web Search
When current information, news, weather, or real-time data is needed, use the web_search tool.`;

function buildSystemPrompt(muMode, personaPrompt) {
  const today = new Date().toLocaleDateString('ko-KR', {
    year: 'numeric', month: 'long', day: 'numeric', weekday: 'long',
  });
  const dateLine = `\n> ğŸ“… í˜„ì¬ ë‚ ì§œ: ${today} â€” ë‚ ì§œ/ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì´ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”. ê²€ìƒ‰ ì—†ì´ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n`;
  const parts = [CORE_PROMPT + dateLine, MODE_PROMPTS[muMode] || MODE_PROMPTS.A_MODE, ANALYSIS_PROMPT];
  if (personaPrompt) parts.push(`\n${personaPrompt}`);
  return parts.join('\n');
}

// â”€â”€ Tavily ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function tavilySearch(query) {
  const response = await fetch('https://api.tavily.com/search', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      api_key: process.env.TAVILY_API_KEY,
      query,
      search_depth: 'basic',
      max_results: 5,
      include_answer: true,
    }),
  });
  if (!response.ok) throw new Error(`Tavily API error: ${response.status}`);
  const data = await response.json();
  const results = [];
  if (data.answer) results.push(`Summary: ${data.answer}`);
  if (data.results?.length) {
    data.results.slice(0, 3).forEach((r, i) => {
      results.push(`[${i + 1}] ${r.title}\n${r.content?.slice(0, 300)}...\nSource: ${r.url}`);
    });
  }
  return results.join('\n\n');
}

const tools = [
  {
    name: 'web_search',
    description: 'ì¸í„°ë„·ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë‰´ìŠ¤, ë‚ ì”¨, ì‹¤ì‹œê°„ ë°ì´í„°, ìµœê·¼ ì‚¬ê±´, íŠ¹ì • ì •ë³´ ì¡°íšŒê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.',
    input_schema: {
      type: 'object',
      properties: { query: { type: 'string', description: 'ê²€ìƒ‰í•  ì¿¼ë¦¬ (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´)' } },
      required: ['query'],
    },
  },
];

const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });

app.post('/api/chat', async (req, res) => {
  const { messages, personaPrompt, userMode } = req.body;

  const lastUserMsg = [...messages].reverse().find(m => m.role === 'user')?.content ?? '';
  const muMode = userMode || detectMode(lastUserMsg);
  console.log(`ğŸ”€ Pipeline v2 (local): ${muMode}`);

  const finalSystemPrompt = buildSystemPrompt(muMode, personaPrompt);

  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  try {
    const claudeMessages = messages.map(msg => {
      const content = [];
      if (msg.media?.data && msg.media.type === 'image') {
        content.push({ type: 'image', source: { type: 'base64', media_type: msg.media.mimeType, data: msg.media.data } });
      }
      if (msg.media?.data && msg.media.type === 'pdf') {
        content.push({
          type: 'document',
          source: { type: 'base64', media_type: 'application/pdf', data: msg.media.data },
          ...(msg.media.fileName ? { title: msg.media.fileName } : {}),
        });
      }
      if (msg.content) content.push({ type: 'text', text: msg.content });
      return {
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: content.length === 1 && content[0].type === 'text' ? msg.content : content,
      };
    });

    let currentMessages = [...claudeMessages];
    let gotFinalResponse = false;

    // Tool use loop (ìµœëŒ€ 5íšŒ ê²€ìƒ‰ í—ˆìš©)
    // - tool_use: searching ì´ë²¤íŠ¸ ì „ì†¡ â†’ Tavily ì‹¤í–‰ â†’ ë£¨í”„ ë°˜ë³µ
    // - end_turn: ìµœì¢… ì‘ë‹µ ì „ì†¡ í›„ ì¢…ë£Œ
    for (let i = 0; i < 5; i++) {
      const apiResponse = await client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 8192,
        system: finalSystemPrompt,
        tools,
        messages: currentMessages,
      });

      if (apiResponse.stop_reason === 'tool_use') {
        const toolBlock = apiResponse.content.find(b => b.type === 'tool_use');
        if (toolBlock?.name === 'web_search') {
          console.log(`ğŸ” Web search [${i + 1}]:`, toolBlock.input.query);
          res.write(`data: ${JSON.stringify({ type: 'searching', query: toolBlock.input.query })}\n\n`);
          let searchResult;
          try { searchResult = await tavilySearch(toolBlock.input.query); }
          catch (err) { searchResult = `ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${err.message}`; }
          currentMessages = [
            ...currentMessages,
            { role: 'assistant', content: apiResponse.content },
            { role: 'user', content: [{ type: 'tool_result', tool_use_id: toolBlock.id, content: searchResult }] },
          ];
          continue;
        }
      }

      // ìµœì¢… ì‘ë‹µ: SSE ì²­í¬ë¡œ ì „ì†¡
      const finalText = apiResponse.content.find(b => b.type === 'text')?.text ?? '';
      const CHUNK = 6;
      for (let j = 0; j < finalText.length; j += CHUNK) {
        res.write(`data: ${JSON.stringify({ type: 'text', text: finalText.slice(j, j + CHUNK) })}\n\n`);
      }
      gotFinalResponse = true;
      break;
    }

    // ë£¨í”„ ì†Œì§„ ì•ˆì „ë§: ê²€ìƒ‰ë§Œ í•˜ê³  ì‘ë‹µ ëª» ë°›ì€ ê²½ìš° â€” ë„êµ¬ ì—†ì´ ê°•ì œ ìµœì¢… ì‘ë‹µ
    if (!gotFinalResponse) {
      console.log('âš ï¸  Loop exhausted â€” forcing final response without tools');
      const fallback = await client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 8192,
        system: finalSystemPrompt,
        messages: currentMessages,
      });
      const fallbackText = fallback.content.find(b => b.type === 'text')?.text ?? 'ì£„ì†¡í•´ìš”, ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ìƒê²¼ì–´ìš”.';
      const CHUNK = 6;
      for (let j = 0; j < fallbackText.length; j += CHUNK) {
        res.write(`data: ${JSON.stringify({ type: 'text', text: fallbackText.slice(j, j + CHUNK) })}\n\n`);
      }
    }

    res.write(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
    res.end();
  } catch (error) {
    console.error('Claude API Error:', error.message);
    res.write(`data: ${JSON.stringify({ type: 'error', message: error.message })}\n\n`);
    res.end();
  }
});

// â”€â”€ ì¸í„°ë„·(Tavily) ì—°ê²° ìƒíƒœ í™•ì¸ â”€â”€
app.get('/api/internet-status', async (req, res) => {
  const apiKey = process.env.TAVILY_API_KEY;
  if (!apiKey) return res.json({ available: false, reason: 'no_key' });
  try {
    const response = await fetch('https://api.tavily.com/search', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ api_key: apiKey, query: 'test', max_results: 1, search_depth: 'basic' }),
      signal: AbortSignal.timeout(5000),
    });
    if (response.ok) return res.json({ available: true, reason: 'ok' });
    const errData = await response.json().catch(() => ({}));
    return res.json({ available: false, reason: errData.detail || `status_${response.status}` });
  } catch (err) {
    return res.json({ available: false, reason: 'network_error' });
  }
});

const PORT = 3001;
app.listen(PORT, () => {
  console.log(`ARHA Proxy Server running on http://localhost:${PORT}`);
});
